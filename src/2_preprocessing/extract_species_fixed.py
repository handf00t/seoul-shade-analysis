#!/usr/bin/env python3
"""
ì„œìš¸ì‹œ ë‚˜ë¬´ ë°ì´í„°ì—ì„œ ìˆ˜ì¢… ëª©ë¡ ì¶”ì¶œ (ì˜¬ë°”ë¥¸ í•„ë“œëª… ì‚¬ìš©)
"""

import requests
import xml.etree.ElementTree as ET
import os
import time
from collections import Counter

API_KEY = os.getenv('SEOUL_API_KEY')
if not API_KEY:
    print("âŒ í™˜ê²½ë³€ìˆ˜ SEOUL_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
    exit(1)

def safe_get_text(element, tag_name, default=""):
    """XMLì—ì„œ ì•ˆì „í•˜ê²Œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    elem = element.find(tag_name)
    if elem is not None and elem.text is not None:
        return elem.text.strip()
    return default

def fetch_xml(url):
    """APIì—ì„œ XML ê°€ì ¸ì˜¤ê¸°"""
    try:
        response = requests.get(url, timeout=30)
        response.raise_for_status()
        root = ET.fromstring(response.content)

        # ì—ëŸ¬ ì²´í¬
        result_code = root.find('.//CODE')
        if result_code is not None and result_code.text not in ['INFO-000']:
            return None

        return root
    except Exception as e:
        return None

def extract_species_from_protected():
    """ë³´í˜¸ìˆ˜ ìˆ˜ì¢… ì¶”ì¶œ (ì˜¬ë°”ë¥¸ í•„ë“œëª…: TRSPC_KORN)"""
    print("ğŸ“¦ ë³´í˜¸ìˆ˜ ìˆ˜ì¢… ì¶”ì¶œ ì¤‘...")
    species_counter = Counter()

    # ì „ì²´ ê°œìˆ˜ í™•ì¸
    count_url = f"http://openAPI.seoul.go.kr:8088/{API_KEY}/xml/GeoInfoNurseTreeOldTreeWGS/1/1"
    count_root = fetch_xml(count_url)

    if not count_root:
        return species_counter

    total_count_elem = count_root.find('.//list_total_count')
    total_count = int(total_count_elem.text) if total_count_elem is not None else 1000

    print(f"  ì „ì²´ ë³´í˜¸ìˆ˜: {total_count}ê±´")

    # ë°°ì¹˜ë¡œ ìˆ˜ì§‘
    batch_size = 1000
    for start_idx in range(1, total_count + 1, batch_size):
        end_idx = min(start_idx + batch_size - 1, total_count)
        url = f"http://openAPI.seoul.go.kr:8088/{API_KEY}/xml/GeoInfoNurseTreeOldTreeWGS/{start_idx}/{end_idx}"

        root = fetch_xml(url)
        if root:
            for row in root.findall('.//row'):
                species = safe_get_text(row, 'TRSPC_KORN', "")  # ì˜¬ë°”ë¥¸ í•„ë“œëª…!
                if species and species != "ë¯¸ìƒ":
                    species_counter[species] += 1

        time.sleep(0.3)
        if start_idx % 1000 == 1:
            print(f"  ì²˜ë¦¬ ì¤‘: {start_idx}/{total_count}")

    print(f"  âœ… ë³´í˜¸ìˆ˜: {len(species_counter)}ê°œ ìˆ˜ì¢…, {sum(species_counter.values())}ê°œì²´")
    return species_counter

def extract_species_from_park():
    """ê³µì›ìˆ˜ëª© ìˆ˜ì¢… ì¶”ì¶œ (ì˜¬ë°”ë¥¸ í•„ë“œëª…: TREE_NM)"""
    print("ğŸ“¦ ê³µì›ìˆ˜ëª© ìˆ˜ì¢… ì¶”ì¶œ ì¤‘...")
    species_counter = Counter()

    # ì „ì²´ ê°œìˆ˜ í™•ì¸
    count_url = f"http://openAPI.seoul.go.kr:8088/{API_KEY}/xml/GeoInfoParkAndPrivateLandWGS/1/1"
    count_root = fetch_xml(count_url)

    if not count_root:
        return species_counter

    total_count_elem = count_root.find('.//list_total_count')
    total_count = int(total_count_elem.text) if total_count_elem is not None else 1000

    print(f"  ì „ì²´ ê³µì›ìˆ˜ëª©: {total_count}ê±´")

    # ë°°ì¹˜ë¡œ ìˆ˜ì§‘ (ì „ì²´ ë°ì´í„°ê°€ ë§ìœ¼ë¯€ë¡œ ìƒ˜í”Œë§)
    batch_size = 1000
    max_samples = min(total_count, 10000)  # ìµœëŒ€ 10000ê±´ë§Œ ìƒ˜í”Œë§

    for start_idx in range(1, max_samples + 1, batch_size):
        end_idx = min(start_idx + batch_size - 1, max_samples)
        url = f"http://openAPI.seoul.go.kr:8088/{API_KEY}/xml/GeoInfoParkAndPrivateLandWGS/{start_idx}/{end_idx}"

        root = fetch_xml(url)
        if root:
            for row in root.findall('.//row'):
                species = safe_get_text(row, 'TREE_NM', "")  # ì˜¬ë°”ë¥¸ í•„ë“œëª…!
                if species and species != "ë¯¸ìƒ":
                    species_counter[species] += 1

        time.sleep(0.3)
        if start_idx % 1000 == 1:
            print(f"  ì²˜ë¦¬ ì¤‘: {start_idx}/{max_samples}")

    print(f"  âœ… ê³µì›ìˆ˜ëª©: {len(species_counter)}ê°œ ìˆ˜ì¢…, {sum(species_counter.values())}ê°œì²´ (ìƒ˜í”Œë§)")
    return species_counter

if __name__ == "__main__":
    print("ğŸŒ³ ì„œìš¸ì‹œ ë‚˜ë¬´ ìˆ˜ì¢… ëª©ë¡ ì¶”ì¶œ ì‹œì‘\n")

    # ê° ì†ŒìŠ¤ë³„ ìˆ˜ì¢… ì¶”ì¶œ
    protected_counter = extract_species_from_protected()
    park_counter = extract_species_from_park()

    # í†µí•©
    all_species_counter = protected_counter + park_counter
    all_species = set(all_species_counter.keys())

    print(f"\n{'='*60}")
    print(f"ì „ì²´ ê³ ìœ  ìˆ˜ì¢… ê°œìˆ˜: {len(all_species)}ê°œ")
    print(f"ì „ì²´ ê°œì²´ ìˆ˜: {sum(all_species_counter.values()):,}ê°œ")
    print(f"{'='*60}")

    # ì•ŒíŒŒë²³ìˆœ ì •ë ¬
    sorted_species = sorted(all_species)

    print("\nğŸ“‹ ì „ì²´ ìˆ˜ì¢… ëª©ë¡ (ê°€ë‚˜ë‹¤ìˆœ):")
    print("-" * 60)
    for i, species in enumerate(sorted_species, 1):
        count = all_species_counter[species]
        print(f"{i:3d}. {species:20s} : {count:,}ê°œ")

    print(f"\nğŸ“Š ìƒìœ„ 30ê°œ ìˆ˜ì¢… (ê°œì²´ ìˆ˜ ê¸°ì¤€):")
    print("-" * 60)
    for i, (species, count) in enumerate(all_species_counter.most_common(30), 1):
        print(f"{i:2d}. {species:20s} : {count:,}ê°œ")

    # íŒŒì¼ë¡œ ì €ì¥
    output_path = '/Users/ashleyson/Downloads/Archive/species_list.txt'
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write("=== ì„œìš¸ì‹œ ë‚˜ë¬´ ì „ì²´ ìˆ˜ì¢… ëª©ë¡ ===\n\n")
        f.write(f"ì´ {len(all_species)}ê°œ ìˆ˜ì¢…\n")
        f.write(f"ì „ì²´ ê°œì²´ ìˆ˜: {sum(all_species_counter.values()):,}ê°œ\n\n")

        f.write("ì „ì²´ ìˆ˜ì¢… ëª©ë¡ (ê°€ë‚˜ë‹¤ìˆœ):\n")
        f.write("-" * 60 + "\n")
        for i, species in enumerate(sorted_species, 1):
            count = all_species_counter[species]
            f.write(f"{i:3d}. {species:20s} : {count:,}ê°œ\n")

        f.write("\n\nìƒìœ„ 30ê°œ ìˆ˜ì¢… (ê°œì²´ ìˆ˜ ê¸°ì¤€):\n")
        f.write("-" * 60 + "\n")
        for i, (species, count) in enumerate(all_species_counter.most_common(30), 1):
            f.write(f"{i:2d}. {species:20s} : {count:,}ê°œ\n")

    print(f"\nâœ… ê²°ê³¼ê°€ {output_path} ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
