#!/usr/bin/env python3
"""
ì„œìš¸ì‹œ ë‚˜ë¬´ ë°ì´í„°ì—ì„œ ìˆ˜ì¢… ëª©ë¡ë§Œ ì¶”ì¶œí•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
"""

import requests
import xml.etree.ElementTree as ET
import os
import time
from collections import Counter

API_KEY = os.getenv('SEOUL_API_KEY')
if not API_KEY:
    print("âŒ í™˜ê²½ë³€ìˆ˜ SEOUL_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
    exit(1)

# ì„œìš¸ì‹œ 25ê°œ êµ¬
DISTRICTS = [
    'ì¢…ë¡œêµ¬', 'ì¤‘êµ¬', 'ìš©ì‚°êµ¬', 'ì„±ë™êµ¬', 'ê´‘ì§„êµ¬', 'ë™ëŒ€ë¬¸êµ¬', 'ì¤‘ë‘êµ¬',
    'ì„±ë¶êµ¬', 'ê°•ë¶êµ¬', 'ë„ë´‰êµ¬', 'ë…¸ì›êµ¬', 'ì€í‰êµ¬', 'ì„œëŒ€ë¬¸êµ¬', 'ë§ˆí¬êµ¬',
    'ì–‘ì²œêµ¬', 'ê°•ì„œêµ¬', 'êµ¬ë¡œêµ¬', 'ê¸ˆì²œêµ¬', 'ì˜ë“±í¬êµ¬', 'ë™ì‘êµ¬', 'ê´€ì•…êµ¬',
    'ì„œì´ˆêµ¬', 'ê°•ë‚¨êµ¬', 'ì†¡íŒŒêµ¬', 'ê°•ë™êµ¬'
]

def safe_get_text(element, tag_name, default=""):
    """XMLì—ì„œ ì•ˆì „í•˜ê²Œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    elem = element.find(tag_name)
    if elem is not None and elem.text is not None:
        return elem.text.strip()
    return default

def fetch_xml(url):
    """APIì—ì„œ XML ê°€ì ¸ì˜¤ê¸°"""
    try:
        response = requests.get(url, timeout=30)
        response.raise_for_status()
        return ET.fromstring(response.content)
    except Exception as e:
        print(f"âŒ API ìš”ì²­ ì‹¤íŒ¨: {e}")
        return None

def extract_species_from_protected():
    """ë³´í˜¸ìˆ˜ ìˆ˜ì¢… ì¶”ì¶œ"""
    print("ğŸ“¦ ë³´í˜¸ìˆ˜ ìˆ˜ì¢… ì¶”ì¶œ ì¤‘...")
    species_set = set()

    url = f"http://openAPI.seoul.go.kr:8088/{API_KEY}/xml/GeoInfoNurseTreeOldTreeWGS/1/1000"
    root = fetch_xml(url)

    if root:
        for row in root.findall('.//row'):
            species = safe_get_text(row, 'TRE_SOM', "ë¯¸ìƒ")
            if species and species != "ë¯¸ìƒ":
                species_set.add(species)

    print(f"  âœ… ë³´í˜¸ìˆ˜: {len(species_set)}ê°œ ìˆ˜ì¢…")
    return species_set

def extract_species_from_roadside():
    """ê°€ë¡œìˆ˜ ìˆ˜ì¢… ì¶”ì¶œ (ì „ì²´ êµ¬)"""
    print("ğŸ“¦ ê°€ë¡œìˆ˜ ìˆ˜ì¢… ì¶”ì¶œ ì¤‘...")
    species_set = set()

    for district in DISTRICTS:
        url = f"http://openAPI.seoul.go.kr:8088/{API_KEY}/xml/GeoInfoOfRoadsideTreeW/1/1000/{district}"
        root = fetch_xml(url)

        if root:
            for row in root.findall('.//row'):
                species = safe_get_text(row, 'WDPT_NM', "ë¯¸ìƒ")
                if species and species != "ë¯¸ìƒ":
                    species_set.add(species)

        time.sleep(0.2)  # API ë¶€í•˜ ë°©ì§€
        print(f"  {district}: {len(species_set)}ê°œ ìˆ˜ì¢… (ëˆ„ì )")

    print(f"  âœ… ê°€ë¡œìˆ˜: {len(species_set)}ê°œ ìˆ˜ì¢…")
    return species_set

def extract_species_from_park():
    """ê³µì›ìˆ˜ëª© ìˆ˜ì¢… ì¶”ì¶œ"""
    print("ğŸ“¦ ê³µì›ìˆ˜ëª© ìˆ˜ì¢… ì¶”ì¶œ ì¤‘...")
    species_set = set()

    url = f"http://openAPI.seoul.go.kr:8088/{API_KEY}/xml/GeoInfoParkAndPrivateLandWGS/1/1000"
    root = fetch_xml(url)

    if root:
        for row in root.findall('.//row'):
            species = safe_get_text(row, 'WDPT_NM', "ë¯¸ìƒ")
            if species and species != "ë¯¸ìƒ":
                species_set.add(species)

    print(f"  âœ… ê³µì›ìˆ˜ëª©: {len(species_set)}ê°œ ìˆ˜ì¢…")
    return species_set

def count_species_occurrences():
    """ê° ìˆ˜ì¢…ì˜ ì¶œí˜„ ë¹ˆë„ ê³„ì‚°"""
    print("\nğŸ“Š ìˆ˜ì¢…ë³„ ê°œì²´ ìˆ˜ ì§‘ê³„ ì¤‘...")
    species_counter = Counter()

    # ë³´í˜¸ìˆ˜
    url = f"http://openAPI.seoul.go.kr:8088/{API_KEY}/xml/GeoInfoNurseTreeOldTreeWGS/1/1000"
    root = fetch_xml(url)
    if root:
        for row in root.findall('.//row'):
            species = safe_get_text(row, 'TRE_SOM', "ë¯¸ìƒ")
            if species and species != "ë¯¸ìƒ":
                species_counter[species] += 1

    # ê°€ë¡œìˆ˜
    for district in DISTRICTS:
        url = f"http://openAPI.seoul.go.kr:8088/{API_KEY}/xml/GeoInfoOfRoadsideTreeW/1/1000/{district}"
        root = fetch_xml(url)
        if root:
            for row in root.findall('.//row'):
                species = safe_get_text(row, 'WDPT_NM', "ë¯¸ìƒ")
                if species and species != "ë¯¸ìƒ":
                    species_counter[species] += 1
        time.sleep(0.2)

    # ê³µì›ìˆ˜ëª©
    url = f"http://openAPI.seoul.go.kr:8088/{API_KEY}/xml/GeoInfoParkAndPrivateLandWGS/1/1000"
    root = fetch_xml(url)
    if root:
        for row in root.findall('.//row'):
            species = safe_get_text(row, 'WDPT_NM', "ë¯¸ìƒ")
            if species and species != "ë¯¸ìƒ":
                species_counter[species] += 1

    return species_counter

if __name__ == "__main__":
    print("ğŸŒ³ ì„œìš¸ì‹œ ë‚˜ë¬´ ìˆ˜ì¢… ëª©ë¡ ì¶”ì¶œ ì‹œì‘\n")

    # ê° ì†ŒìŠ¤ë³„ ìˆ˜ì¢… ì¶”ì¶œ
    protected_species = extract_species_from_protected()
    roadside_species = extract_species_from_roadside()
    park_species = extract_species_from_park()

    # ì „ì²´ ìˆ˜ì¢… í†µí•©
    all_species = protected_species | roadside_species | park_species

    print(f"\n{'='*60}")
    print(f"ì „ì²´ ê³ ìœ  ìˆ˜ì¢… ê°œìˆ˜: {len(all_species)}ê°œ")
    print(f"{'='*60}")

    # ì•ŒíŒŒë²³ìˆœ ì •ë ¬
    sorted_species = sorted(all_species)

    print("\nğŸ“‹ ì „ì²´ ìˆ˜ì¢… ëª©ë¡ (ê°€ë‚˜ë‹¤ìˆœ):")
    print("-" * 60)
    for i, species in enumerate(sorted_species, 1):
        print(f"{i:3d}. {species}")

    # ë¹ˆë„ìˆ˜ ê³„ì‚°
    species_counts = count_species_occurrences()

    print(f"\nğŸ“Š ìƒìœ„ 20ê°œ ìˆ˜ì¢… (ê°œì²´ ìˆ˜ ê¸°ì¤€):")
    print("-" * 60)
    for i, (species, count) in enumerate(species_counts.most_common(20), 1):
        print(f"{i:2d}. {species:20s} : {count:,}ê°œ")

    # íŒŒì¼ë¡œ ì €ì¥
    with open('/Users/ashleyson/Downloads/Archive/species_list.txt', 'w', encoding='utf-8') as f:
        f.write("=== ì„œìš¸ì‹œ ë‚˜ë¬´ ì „ì²´ ìˆ˜ì¢… ëª©ë¡ ===\n\n")
        f.write(f"ì´ {len(all_species)}ê°œ ìˆ˜ì¢…\n\n")
        f.write("ìˆ˜ì¢… ëª©ë¡ (ê°€ë‚˜ë‹¤ìˆœ):\n")
        for species in sorted_species:
            f.write(f"- {species}\n")

        f.write("\n\nìƒìœ„ 20ê°œ ìˆ˜ì¢… (ê°œì²´ ìˆ˜ ê¸°ì¤€):\n")
        for i, (species, count) in enumerate(species_counts.most_common(20), 1):
            f.write(f"{i:2d}. {species:20s} : {count:,}ê°œ\n")

    print(f"\nâœ… ê²°ê³¼ê°€ /Users/ashleyson/Downloads/Archive/species_list.txt ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
